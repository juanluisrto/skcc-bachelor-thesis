{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Activation\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "def text_detection_model(channels=8):\n",
    "    \"\"\" Defines a simple CNN that inputs an image and outputs a binary mask. \"\"\"\n",
    "\n",
    "    input_shape = (160, 160, 1)\n",
    "    batch_size = 1\n",
    "    activation = 'relu'\n",
    "    padding = 'same'\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(channels, (5, 5), padding=padding, activation=activation, batch_size=batch_size, input_shape=input_shape))\n",
    "    model.add(Conv2D(channels, (5, 5), activation=activation, padding=padding))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(channels, (5, 5), activation=activation, padding=padding))\n",
    "    model.add(Conv2D(channels * 2, (5, 5), activation=activation, padding=padding))\n",
    "    model.add(Conv2D(channels * 2, (5, 5), activation=activation, padding=padding))\n",
    "    model.add(Conv2D(channels * 2, (5, 5), activation=activation, padding=padding))\n",
    "    model.add(Conv2D(channels * 2, (5, 5), activation=activation, padding=padding))\n",
    "    model.add(Conv2D(256, (1, 1), activation=activation, padding=padding))    \n",
    "\n",
    "    model.add(Conv2D(1, (1, 1), activation='sigmoid', padding=padding))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generator import StringGenerator, StringImageBatchGenerator, StringRenderer\n",
    "\n",
    "string_generator = StringGenerator()\n",
    "string_renderer = StringRenderer(image_size=(160, 160),\n",
    "                                 target_size=(80, 80),\n",
    "                                 max_background_mixture=0.8,\n",
    "                                 max_noise_sigma=0.04,\n",
    "                                 fonts_folder='fonts',\n",
    "                                 backgrounds_folder='backgrounds')\n",
    "data_generator = StringImageBatchGenerator(string_generator=string_generator, \n",
    "                                           string_renderer=string_renderer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = data_generator.get_batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_image(i):\n",
    "    image = images[i,:,:,0]\n",
    "    target = targets[i,:,:,0]\n",
    "    plt.figure()\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='bilinear')\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.imshow(target, cmap=plt.cm.gray_r, interpolation='bilinear')\n",
    "    plt.show()\n",
    "    \n",
    "interact(view_image, i=(0, len(images) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Building model\")\n",
    "model_channels = 32\n",
    "model = text_detection_model(model_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "steps_per_epoch = 16\n",
    "validation_image = 2048\n",
    "num_epochs = 20000\n",
    "\n",
    "print(\"Generating validation set\")\n",
    "val_data = data_generator.get_batch(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "check_point_callback = ModelCheckpoint('best_model.h5',\n",
    "                                       monitor='val_loss',\n",
    "                                       verbose=1,\n",
    "                                       save_best_only=True, \n",
    "                                       mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Starting training\")\n",
    "\n",
    "model.fit_generator(generator=data_generator.generate(),\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=val_data,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks=[check_point_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model graph to a .tflite file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a prunned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    prunned so subgraphs that are not neccesary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n",
    "                                                      output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import subprocess\n",
    "tf.contrib.lite.tempfile = tempfile\n",
    "tf.contrib.lite.subprocess = subprocess\n",
    "\n",
    "frozen_graphdef = freeze_session(K.get_session(), output_names=[model.output.op.name])\n",
    "\n",
    "tflite_model = tf.contrib.lite.toco_convert(frozen_graphdef, model.inputs, model.outputs)\n",
    "\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export model graph to a .pb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "sess = K.get_session()\n",
    "FREEZE_DIR = 'frozen'\n",
    "\n",
    "frozen_graph = freeze_session(K.get_session(), output_names=[model.output.op.name])\n",
    "tf.train.write_graph(frozen_graph, './', \"skcc_model.pb\", as_text=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View trained model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def view_image(i):\n",
    "    image = images[i,:,:,0]\n",
    "    target = targets[i,:,:,0]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='bilinear')\n",
    "    plt.title('Input image')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(target, cmap=plt.cm.gray_r, interpolation='bilinear')\n",
    "    plt.title('Target')\n",
    "    plt.show()\n",
    "    \n",
    "    input_img = np.expand_dims(image, axis=2)\n",
    "    input_img = np.expand_dims(input_img, axis=0)\n",
    "    \n",
    "    prediction = model.predict(input_img)[0,:,:,0]\n",
    "    plt.figure()\n",
    "    plt.imshow(prediction, cmap=plt.cm.gray_r, interpolation='bilinear')\n",
    "    plt.title('Prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = interact(view_image, i=(0, len(images) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "import glob\n",
    "from image import normalize_pixels\n",
    "from ipywidgets import interact\n",
    "\n",
    "test_images_folder = 'test_images'\n",
    "\n",
    "test_image_files = list(glob.iglob('{}/*.jpg'.format(test_images_folder)))\n",
    "test_image_files += list(glob.iglob('{}/*.png'.format(test_images_folder)))\n",
    "test_image_files += list(glob.iglob('{}/*.jpeg'.format(test_images_folder)))\n",
    "\n",
    "IMAGE_WIDTH = 520\n",
    "\n",
    "\n",
    "def view_image(i):\n",
    "    \n",
    "    test_image_file = test_image_files[i]\n",
    "    test_image = io.imread(test_image_file, as_gray=True)\n",
    "\n",
    "    if test_image.shape[1] > IMAGE_WIDTH:\n",
    "        size = (np.int32(test_image.shape[0] * IMAGE_WIDTH / test_image.shape[1]), IMAGE_WIDTH)\n",
    "        test_image = np.float32(transform.resize(test_image, size, mode='reflect'))\n",
    "\n",
    "\n",
    "    image = normalize_pixels(test_image)\n",
    "    print(image.shape)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='bilinear')\n",
    "    plt.show()\n",
    "    \n",
    "    input_img = np.expand_dims(np.expand_dims(image, axis=2), axis=0)\n",
    "    prediction = model.predict(input_img)[0,:,:,0]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(prediction, cmap=plt.cm.gray_r, interpolation='bilinear')\n",
    "    plt.title('Prediction raw')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    prediction[prediction < 0.5] = 0\n",
    "    plt.figure()\n",
    "    plt.imshow(prediction, cmap=plt.cm.gray_r, interpolation='bilinear')\n",
    "    plt.title('Prediction cleaned up')\n",
    "    plt.show()\n",
    "    \n",
    "q = interact(view_image, i=(0, len(test_image_files) - 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
